!obj:pylearn2.train.Train {
    dataset: &train !obj:pylearn2.scripts.papers.maxout.norb.load_norb_instance_dataset {
      dataset_path: "${PYLEARN2_DATA_PATH}/norb/instance_recognition/norb_left_02_00_gcn_zca_train.pkl",
      convert_to_one_hot: True
      #use_norb_labels: True
    },
    model: !obj:pylearn2.models.mlp.MLP {
        batch_size: 1, #16, # cuda-convnet only optimized for multiples of 128, but we run out of memory at that batch size. See: http://deeplearning.net/software/pylearn2/library/alex.html
        #42,  # norb image vectors are 3x the size cifar ones. Batch size was 128 for cifar, so we use 128/3 = 42 1/3 ~= 42
        layers: [
                 !obj:pylearn2.models.maxout.MaxoutConvC01B {
                     layer_name: 'h0',
                     pad: 3, #4, # this should be half of the kernel size
                     tied_b: 1,
                     W_lr_scale: .05,
                     b_lr_scale: .05,
                     num_channels: 96, #192, #96,
                     num_pieces: 2,
                     kernel_shape: [6, 6], # [8, 8],
                     pool_shape: [24, 24],  # [12, 12]. was [4, 4] for cifar 10, but NORB images are 3x as tall and wide.
                     pool_stride: [6, 6],  # was [2, 2] for cifar10, but NORB images are 3x as tall and wide.
                     irange: &common_irange .05,  # .005, .01
                     max_kernel_norm: .9,
                     partial_sum: 109,  # was 33 for cifar10. Seems to be (image_height or image_width) + 1.
                 },
                 !obj:pylearn2.models.maxout.MaxoutConvC01B {
                     layer_name: 'h1',
                     pad: 3,  # weird that this is 3, not kernel_shape/2
                     tied_b: 1,
                     W_lr_scale: .05,
                     b_lr_scale: .05,
                     num_channels: 192, #384, #192,
                     num_pieces: 2,
                     kernel_shape: [6, 6], # [8, 8]
                     pool_shape: [8, 8], # [4, 4],
                     pool_stride: [3, 3],  # [2, 2] changed to 3,3 so that the product of strides cleanly divides the image size
                     irange: *common_irange,
                     max_kernel_norm: 1.9365,
                     partial_sum: 17, #17, # 15
                 },
                 !obj:pylearn2.models.maxout.MaxoutConvC01B {
                     pad: 3,
                     layer_name: 'h2',
                     tied_b: 1,
                     W_lr_scale: .05,
                     b_lr_scale: .05,
                     num_channels: 192,
                     num_pieces: 2,
                     kernel_shape: [5, 5],
                     pool_shape: [4, 4],#[2, 2],
                     pool_stride: [2, 2],
                     irange: *common_irange,
                     max_kernel_norm: 1.9365,
                 },
                 !obj:pylearn2.models.maxout.Maxout {
                    layer_name: 'h3',
                    irange: *common_irange,
                    num_units: 500, #2500, #500,
                    num_pieces: 5,
                    max_col_norm: 1.9
                 },
                 !obj:pylearn2.models.mlp.Softmax {
                     max_col_norm: 1.9365,
                     layer_name: 'y',
                     n_classes: 50,
                     irange: *common_irange
                 }
                 # Output: 50
                ],
        input_space: !obj:pylearn2.space.Conv2DSpace {
            shape: &window_shape [108, 108],
            num_channels: 1,
            axes: ['c', 0, 1, 'b'],
        },
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        learning_rate: .17, #.08,  # .17
        init_momentum: .5,
        train_iteration_mode: 'even_sequential',
        monitor_iteration_mode: 'even_sequential',
        monitoring_dataset:
        {
        # this feels cheaty: using the test set as validation. maxout's cifar10.yaml does it, but the real thing to do is probably split the test set into two, and use one for validation and the other for testing?
          'valid' : !obj:pylearn2.scripts.papers.maxout.norb.load_norb_instance_dataset {
            dataset_path: "${PYLEARN2_DATA_PATH}/norb/instance_recognition/norb_left_02_00_gcn_zca_test.pkl",
            convert_to_one_hot: True
            # use_norb_labels: False
            },
          'test' : &valid !obj:pylearn2.scripts.papers.maxout.norb.load_norb_instance_dataset {
            dataset_path: "${PYLEARN2_DATA_PATH}/norb/instance_recognition/norb_left_02_00_gcn_zca_test.pkl",
            convert_to_one_hot: True
            # use_norb_labels: False
            },
        },

        # monitoring_dataset:
        #     {
        #         'test' : &valid !obj:pylearn2.datasets.zca_dataset.ZCA_Dataset {
        # preprocessed_dataset: !pkl: "${PYLEARN2_DATA_PATH}/norb_small/instance_recognition/small_norb_02_00_test.pkl",
        # preprocessor: !pkl: "${PYLEARN2_DATA_PATH}/norb_small/instance_recognition/small_norb_02_00_preprocessor.pkl",
        # axes: ['c', 0, 1, 'b']
        #                   },
        #     },
        cost: !obj:pylearn2.costs.mlp.dropout.Dropout {
            input_include_probs: { 'h0' : .8 },
            input_scales: { 'h0' : 1. }
        },
        termination_criterion: !obj:pylearn2.termination_criteria.And {
            criteria: [
                !obj:pylearn2.termination_criteria.MonitorBased {
                    channel_name: "valid_y_misclass",
                    prop_decrease: 0.01, # 0.,
                    N: 20 # 100
                },
                !obj:pylearn2.termination_criteria.EpochCounter {
                    max_epochs: &max_num_epochs 200 # 474, 100
                }
            ]
        },
    },
    extensions: [
        !obj:pylearn2.training_algorithms.sgd.MomentumAdjustor {
            start: 1,
            saturate: 50, #*max_num_epochs, # 250,
            final_momentum: .65
        },
        !obj:pylearn2.training_algorithms.sgd.LinearDecayOverEpoch {
            start: 1,  # start decaying on this epoch
            saturate: *max_num_epochs, # 500,
            decay_factor: .01  # final learning rate = initial rate times this.
        },
        # WindowAndFlip currently makes a copy of the database in RAM. 
        # Can't allow that. Uncomment once this behavior is fixed.
        # !obj:pylearn2.train_extensions.window_flip.WindowAndFlipC01B {
        #     pad_randomized: 8,
        #     window_shape: *window_shape,
        #     randomize: [ *train],
        #     center: [ *valid ]
        # },
        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
            channel_name: 'valid_y_misclass',
            save_path: 'norb_small_best.pkl'
        }
        # ,
        # !obj:pylearn2.train_extensions.EpochLogger {
        #   output_dir : "epoch_snapshots",
        #   save_models : False,
        #   save_images : True
        # }
    ],
    save_path: "${PYLEARN2_TRAIN_FILE_FULL_STEM}.pkl",
    save_freq: 1
}
