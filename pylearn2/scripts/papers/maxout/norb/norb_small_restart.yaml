!obj:pylearn2.train.Train {
    dataset: &train !obj:pylearn2.scripts.papers.maxout.norb.load_norb_instance_dataset {
      dataset_path: "${PYLEARN2_DATA_PATH}/norb_small/instance_recognition/left_02_01/gcn-zca_train.pkl",
      label_format: "obj_onehot",
      axes: &common_axes ['c', 0, 1, 'b']
    },
    model: !obj:pylearn2.monitor.push_monitor {
      model: !pkl: "norb_maxout_experiments/2014_09_03_0.067_error/norb_small.pkl",
      name: "monitor_validation"
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
    # norb_small.yaml crashed after 41 epochs, leaving the following learning rate and momentum
        learning_rate: .034588, # 0.04 + (0.0004 - .04) * (41./300)
        init_momentum: .623, # 0.5 + (0.65 - 0.5) * (41./50) 
        train_iteration_mode: 'even_sequential',
        monitor_iteration_mode: 'even_sequential',
        monitoring_dataset:
        {
        # this feels cheaty: using the test set as validation. maxout's cifar10.yaml does it, but the real thing to do is probably split the test set into two, and use one for validation and the other for testing?
          'valid' : !obj:pylearn2.scripts.papers.maxout.norb.load_norb_instance_dataset {
            dataset_path: "${PYLEARN2_DATA_PATH}/norb_small/instance_recognition/left_02_01/gcn-zca_test.pkl",
            label_format: "obj_onehot",
            axes: *common_axes
            },
          'test' : &valid !obj:pylearn2.scripts.papers.maxout.norb.load_norb_instance_dataset {
            dataset_path: "${PYLEARN2_DATA_PATH}/norb_small/instance_recognition/left_02_01/gcn-zca_test.pkl",
            label_format: "obj_onehot",
            axes: *common_axes
            },
        },
        cost: !obj:pylearn2.costs.mlp.dropout.Dropout {
            input_include_probs: { 'h0' : .8 },
            input_scales: { 'h0' : 1. }
        },
        termination_criterion: !obj:pylearn2.termination_criteria.And {
            criteria: [
                !obj:pylearn2.termination_criteria.MonitorBased {
                    channel_name: "valid_y_misclass",
                    prop_decrease: 0.01, # 0.,
                    N: 20 # 100
                },
                !obj:pylearn2.termination_criteria.EpochCounter {
                    max_epochs: &max_num_epochs 300 # 300 - 41 + extra = 300
                }
            ]
        },
    },
    extensions: [
    # norb_small.yaml crashed after seeing 41 epochs; initialize
    # MomentumAdjustor and LinearDecayOverEpoch accordingly.
        !obj:pylearn2.training_algorithms.sgd.MomentumAdjustor {
            start: 1,  # start adjusting on this epoch
            saturate: 9, # 50 - 41
            final_momentum: .65
        },
        !obj:pylearn2.training_algorithms.sgd.LinearDecayOverEpoch {
            start: 1,  # start decaying on this epoch
            saturate: 259,  # 300 - 41
            decay_factor: .0115647  # final learning rate = initial rate times this. This value chosen so that the final learning rate is .004, as originally planned by norb_small.yaml
        },
        !obj:pylearn2.train_extensions.window_flip.WindowAndFlipC01B {
            pad_randomized: 5,  # matches max perturbation used by big NORB
            window_shape: &window_shape [96, 96],
            randomize: [ *train],
            center: [ *valid ]
        },
        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
            channel_name: 'valid_y_misclass',
            save_path: 'norb_maxout_experiments/${PYLEARN2_TRAIN_FILE_FULL_STEM}_best.pkl',
            tag_key: 'restarted'
        }
        # ,
        # !obj:pylearn2.train_extensions.EpochLogger {
        #   output_dir : "epoch_snapshots",
        #   save_models : False,
        #   save_images : True
        # }
    ],
    save_path: "norb_maxout_experiments/${PYLEARN2_TRAIN_FILE_FULL_STEM}.pkl",
    save_freq: 1
}
